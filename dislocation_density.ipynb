{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc50bb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import hdf5plugin\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "\n",
    "def get_mu(h5_file_path):\n",
    "    mu = []\n",
    "    with h5py.File(h5_file_path, 'r') as file:\n",
    "        for item in file['1.1/instrument/mu']:\n",
    "            item_str = str(item)\n",
    "            mu.append(file['1.1/instrument/mu/' + item_str][()])\n",
    "    return mu\n",
    "\n",
    "def image_stack_from_hdf(filename):\n",
    "    try:\n",
    "        with h5py.File(filename, 'r') as f:\n",
    "            dataset = f['entry_0000/measurement/data']\n",
    "            image_stack = np.array(dataset)\n",
    "\n",
    "            for i, frame in enumerate(image_stack):\n",
    "                noise_floor = 107  # got better result with 107\n",
    "                image_stack[i][image_stack[i] < noise_floor] = 0\n",
    "\n",
    "            for i, frame in enumerate(image_stack):\n",
    "                sigma = 1\n",
    "                image_stack[i] = scipy.ndimage.gaussian_filter(frame, sigma)\n",
    "\n",
    "            return image_stack\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "        return None\n",
    "\n",
    "def com(image_stack, mu_list):\n",
    "    max_indices = np.argmax(image_stack, axis=0)\n",
    "\n",
    "    mu_array = np.array(mu_list).flatten()\n",
    "    mu_map = mu_array[max_indices]\n",
    "\n",
    "   \n",
    "    mu_map_normalized = (mu_map - np.min(mu_map))\n",
    "\n",
    "   \n",
    "    midpoint = np.median(mu_map_normalized)\n",
    "    mu_map_normalized -= midpoint\n",
    "\n",
    "    \n",
    "    top_rows_to_mask = 560\n",
    "    bottom_rows_to_mask = 780\n",
    "\n",
    "   \n",
    "    mu_map_normalized[:top_rows_to_mask, :] = np.nan\n",
    "    mu_map_normalized[-bottom_rows_to_mask:, :] = np.nan\n",
    "\n",
    "   \n",
    "    vmin = -np.max(np.abs(mu_map_normalized))\n",
    "    vmax = np.max(np.abs(mu_map_normalized))\n",
    "\n",
    "    \n",
    "    height, width = mu_map_normalized.shape\n",
    "    extent = [0, width * 0.15, height * 0.15, 0]\n",
    "\n",
    "   \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    cax = ax.imshow(mu_map_normalized, cmap='RdBu', vmin=vmin, vmax=vmax, extent=extent)\n",
    "    cbar = fig.colorbar(cax)\n",
    "\n",
    "    # Set font sizes\n",
    "    ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "    ax.set_xlabel('X (µm)', fontsize=20)\n",
    "    ax.set_ylabel('Y (µm)', fontsize=20)\n",
    "    ax.set_title('Mu Map (Normalized, Centered at Zero)', fontsize=20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return max_indices, mu_map_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfc1ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_stack_path = r'C:\\Users\\Admin\\Downloads\\Fe_C_19_2keVrocking\\scan0012\\pco_ff_0000.h5'\n",
    "mu_list_path = r'C:\\Users\\Admin\\Downloads\\Fe_C_19_2keVrocking\\Fe-C_19_2_keV_10x_layer_rocking.h5'\n",
    "\n",
    "\n",
    "image_stack = image_stack_from_hdf(image_stack_path)\n",
    "mu_list = get_mu(mu_list_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b9cf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_stack_path = 'G:/My Drive/Fe-C-H_farfield/Fe-C-H_farfield_10x_mosalayers_corrected/scan0012/pco_ff_0000.h5'\n",
    "mu_list_path = 'G:/My Drive/Fe-C-H_farfield/Fe-C-H_farfield_10x_mosalayers_corrected/Fe-C-H_farfield_10x_mosalayers_corrected.h5'\n",
    "\n",
    "\n",
    "image_stack = image_stack_from_hdf(image_stack_path)\n",
    "mu_list = get_mu(mu_list_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeea162",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_composite_image(image_stack):\n",
    "    \"\"\"\n",
    "    Sum all images in the stack to create a composite dark field image.\n",
    "    This enhances contrast features present across multiple frames.\n",
    "    \"\"\"\n",
    "    if image_stack is None:\n",
    "        print(\"Error: No image stack provided\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Summing {len(image_stack)} images...\")\n",
    "    \n",
    "    \n",
    "    composite_image = np.sum(image_stack, axis=0)\n",
    "    \n",
    "    \n",
    "    composite_image = composite_image.astype(np.float64)\n",
    "    \n",
    "    \n",
    "    composite_image = scipy.ndimage.gaussian_filter(composite_image, sigma=0.8)\n",
    "    \n",
    "    p2, p98 = np.percentile(composite_image, (2, 98))\n",
    "    composite_image = np.clip(composite_image, p2, p98)\n",
    "    composite_image = (composite_image - p2) / (p98 - p2)\n",
    "    \n",
    "    return composite_image\n",
    "\n",
    "composite_image = create_composite_image(image_stack)\n",
    "\n",
    "if composite_image is not None:\n",
    "   \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    \n",
    "    ax1.imshow(image_stack[len(image_stack)//2], cmap='gray')\n",
    "    ax1.set_title('Single Frame (Middle)', fontsize=14)\n",
    "    ax1.set_xlabel('Pixels', fontsize=12)\n",
    "    ax1.set_ylabel('Pixels', fontsize=12)\n",
    "    \n",
    "    \n",
    "    im2 = ax2.imshow(composite_image, cmap='gray')\n",
    "    ax2.set_title('Composite Image (All Frames Summed)', fontsize=14)\n",
    "    ax2.set_xlabel('Pixels', fontsize=12)\n",
    "    ax2.set_ylabel('Pixels', fontsize=12)\n",
    "    \n",
    "    \n",
    "    plt.colorbar(im2, ax=ax2, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Composite image shape: {composite_image.shape}\")\n",
    "    print(f\"Pixel size: 0.15 μm/pixel\")\n",
    "    print(f\"Field of view: {composite_image.shape[1] * 0.15:.1f} × {composite_image.shape[0] * 0.15:.1f} μm²\")\n",
    "else:\n",
    "    print(\"Failed to create composite image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18f81c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_dislocation_density(image, pixel_size_um=0.15, grid_spacing_pixels=50, \n",
    "                                threshold_method='otsu', morphology_operations=True, crop_region=None):\n",
    "\n",
    "    from skimage import filters, feature, morphology, measure\n",
    "    from scipy import ndimage\n",
    "    \n",
    "    if image is None:\n",
    "        return None, None, None\n",
    "    \n",
    "    \n",
    "    if crop_region is not None:\n",
    "        y_start, y_end = crop_region\n",
    "        original_shape = image.shape\n",
    "        image = image[y_start:y_end, :]\n",
    "        print(f\"Image cropped from {original_shape} to {image.shape}\")\n",
    "        print(f\"Cropped region: rows {y_start}-{y_end} (vertical: {y_start*pixel_size_um:.1f}-{y_end*pixel_size_um:.1f} μm)\")\n",
    "    \n",
    "   \n",
    "    from skimage import exposure\n",
    "    \n",
    "   \n",
    "    p2, p98 = np.percentile(image, (2, 98))\n",
    "    img_stretched = exposure.rescale_intensity(image, in_range=(p2, p98))\n",
    "    \n",
    "    img_enhanced = exposure.equalize_adapthist(img_stretched, clip_limit=0.03)\n",
    "    \n",
    "    working_image = image\n",
    "    threshold_method_clean = threshold_method\n",
    "        \n",
    "    \n",
    "    # Analyze image statistics\n",
    "    img_mean = np.mean(working_image)\n",
    "    img_std = np.std(working_image)\n",
    "    img_min = np.min(working_image)\n",
    "    img_max = np.max(working_image)\n",
    "    \n",
    "    print(f\"Image statistics - Mean: {img_mean:.4f}, Std: {img_std:.4f}\")\n",
    "    print(f\"Image range - Min: {img_min:.4f}, Max: {img_max:.4f}\")\n",
    "    \n",
    "    \n",
    "    if threshold_method_clean == 'otsu':\n",
    "        threshold = filters.threshold_otsu(working_image)\n",
    "        print(f\"Otsu threshold: {threshold:.4f}\")\n",
    "    \n",
    "        # Local adaptive thresholding\n",
    "        from skimage.filters import threshold_local\n",
    "        threshold_map = threshold_local(working_image, block_size=51, method='mean', offset=0.01)\n",
    "        edges = working_image > threshold_map\n",
    "        threshold = np.mean(threshold_map)  \n",
    "        print(f\"Local Otsu threshold (mean): {threshold:.4f}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    if threshold_method_clean != 'local_otsu':\n",
    "        edges = working_image > threshold\n",
    "    \n",
    "    print(f\"Percentage of pixels above threshold: {np.sum(edges) / edges.size * 100:.2f}%\")\n",
    "    \n",
    "    \n",
    "    edges_dis = edges.copy()  \n",
    " \n",
    "\n",
    "    edges_for_analysis = edges_dis\n",
    "    \n",
    "    \n",
    "    \n",
    "    height, width = image.shape\n",
    "    grid_lines = []\n",
    "    \n",
    "    # Horizontal lines\n",
    "    for y in range(grid_spacing_pixels, height, grid_spacing_pixels):\n",
    "        grid_lines.append(('horizontal', y, 0, width))\n",
    "    \n",
    "    # Vertical lines\n",
    "    for x in range(grid_spacing_pixels, width, grid_spacing_pixels):\n",
    "        grid_lines.append(('vertical', 0, x, height))\n",
    "    \n",
    "    print(f\"Created {len(grid_lines)} grid lines\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    total_intersections = 0\n",
    "    total_grid_length_pixels = 0\n",
    "    \n",
    "    for line_type, start_coord, fixed_coord, end_coord in grid_lines:\n",
    "        if line_type == 'horizontal':\n",
    "            \n",
    "            y = start_coord\n",
    "            if 0 <= y < height:\n",
    "                line_pixels = edges_for_analysis[y, :]  \n",
    "                total_grid_length_pixels += width\n",
    "                \n",
    "                intersections = np.sum(line_pixels)  \n",
    "                total_intersections += intersections\n",
    "        else:  \n",
    "            x = fixed_coord\n",
    "            if 0 <= x < width:\n",
    "                line_pixels = edges_for_analysis[:, x]  \n",
    "                \n",
    "                intersections = np.sum(line_pixels)  \n",
    "                total_intersections += intersections\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    feature_density = np.sum(edges_for_analysis) / edges_for_analysis.size\n",
    "    print(f\"Feature density: {feature_density:.4f} ({feature_density*100:.2f}% of image)\")\n",
    "    \n",
    "  \n",
    "    expected_intersections_alt = int(total_grid_length_pixels * feature_density)\n",
    "    print(f\"Expected intersections from density: {expected_intersections_alt}\")\n",
    "    \n",
    "    \n",
    "    # Convert measurements to micrometers\n",
    "    total_grid_length_um = total_grid_length_pixels * pixel_size_um\n",
    "    \n",
    "    \n",
    "    if total_grid_length_um > 0:\n",
    "        # Base calculation\n",
    "        base_density_per_um = total_intersections / (2 * total_grid_length_um)\n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "        fine_grid_factor = 3.0 \n",
    "        \n",
    "        \n",
    "        darkfield_factor = 2.5  \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        print(f\"  Base density: {base_density_per_um:.2e} /μm\")\n",
    "        \n",
    "        \n",
    "    \n",
    "    fig, axes = plt.subplots(3, 2, figsize=(16, 18))\n",
    "    \n",
    "    axes[0,0].imshow(image, cmap='gray')\n",
    "    axes[0,0].set_title('Original Composite Image', fontsize=14)\n",
    "    axes[0,0].set_xlabel('Pixels', fontsize=12)\n",
    "    axes[0,0].set_ylabel('Pixels', fontsize=12)\n",
    "    \n",
    "    axes[0,1].imshow(working_image, cmap='gray')\n",
    "    axes[0,1].set_title('Preprocessed Image', fontsize=14)\n",
    "    axes[0,1].set_xlabel('Pixels', fontsize=12)\n",
    "    axes[0,1].set_ylabel('Pixels', fontsize=12)\n",
    "    \n",
    "    \n",
    "    axes[1,0].hist(image.flatten(), bins=100, alpha=0.7, density=True, label='Original', color='blue')\n",
    "    axes[1,0].hist(working_image.flatten(), bins=100, alpha=0.7, density=True, label='Preprocessed', color='orange')\n",
    "    axes[1,0].axvline(threshold, color='red', linestyle='--', linewidth=2, label=f'Threshold: {threshold:.4f}')\n",
    "    axes[1,0].set_title('Intensity Histograms with Threshold', fontsize=14)\n",
    "    axes[1,0].set_xlabel('Intensity', fontsize=12)\n",
    "    axes[1,0].set_ylabel('Density', fontsize=12)\n",
    "    axes[1,0].legend()\n",
    "    \n",
    "    \n",
    "    axes[2,1].imshow(edges_for_analysis, cmap='gray', alpha=0.9)\n",
    "    \n",
    "   \n",
    "    grid_lines_to_show = []\n",
    "    \n",
    "    height, width = edges_for_analysis.shape\n",
    "    \n",
    "    # Horizontal lines\n",
    "    for y in range(grid_spacing_pixels, height, grid_spacing_pixels):\n",
    "        grid_lines_to_show.append(('horizontal', y))\n",
    "    \n",
    "    # Vertical lines  \n",
    "    for x in range(grid_spacing_pixels, width, grid_spacing_pixels):\n",
    "        grid_lines_to_show.append(('vertical', x))\n",
    "    \n",
    "    print(f\"Total grid lines to display: {len(grid_lines_to_show)}\")\n",
    "    \n",
    "\n",
    "    for i, (line_type, coord) in enumerate(grid_lines_to_show[::step]):\n",
    "        if line_type == 'horizontal':\n",
    "            axes[2,1].axhline(y=coord, color='red', alpha=0.7, linewidth=0.8)\n",
    "        else:\n",
    "            axes[2,1].axvline(x=coord, color='red', alpha=0.7, linewidth=0.8)\n",
    "    \n",
    "    axes[2,1].set_title(f'Grid Analysis ({total_intersections} intersections, {grid_spacing_pixels}px={grid_spacing_pixels*pixel_size_um:.0f}nm spacing)', fontsize=14)\n",
    "    axes[2,1].set_xlabel('Pixels', fontsize=12)\n",
    "    axes[2,1].set_ylabel('Pixels', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
